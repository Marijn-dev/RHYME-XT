program: train_wandb_sweep.py
project: LIF_L1_sweep
method: bayes # Bayesian Optimization
metric:
  name: val_loss # name of the metric to minimize
  goal: minimize

parameters:
  control_rnn_size:
    values: [64, 128, 150, 200, 250]

  control_rnn_depth:
    values: [1, 2]

  encoder_size:
    values: [1, 2]

  encoder_depth:
    values: [1, 2]

  decoder_size:
    values: [1, 2, 3]

  decoder_depth:
    values: [1, 2, 3]

  batch_size:
    values: [32, 64, 128, 256]

  unfreeze_epoch:
    values: [0, 10, 100, 1000]

  use_nonlinear:
    values: [true, false]

  IC_encoder_decoder:
    values: [true, false]

  regular:
    values: [false] # True: standard flow model

  use_conv_encoder:
    values: [false]

  trunk_modes:
    values: [100, 150, 200, 250]

  trunk_size_svd: # fixed
    values: [[100, 100, 100, 100]]

  trunk_size_extra: # fixed
    values: [[100, 100], [100, 100, 100], [100, 100, 100, 100]]

  NL_size:
    values: [[20, 20, 20, 20], [50, 50], [100, 100], [50, 50, 50]] # hidden size of nonlinearity at end, only used if use_nonlinear is True

  train_loss:
    values: ["MSE", "MSE_orthogonal", "L1", "L1_orthogonal"]

  val_loss:
    values: ["L1"]

  n_epochs:
    values: [1000]

  es_patience:
    values: [30]

  es_delta:
    values: [1e-7]

  sched_patience:
    values: [5]

  sched_factor:
    values: [2]

  lr:
    min: 1e-4
    max: 1e-3
    distribution: log_uniform_values

  max_seq_len:
    values: [10, 20, 50, -1]

  n_samples:
    values: [1, 2, 4]
